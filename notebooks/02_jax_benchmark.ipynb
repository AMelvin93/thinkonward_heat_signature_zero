{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX Heat Simulator Benchmark\n",
    "\n",
    "This notebook tests and benchmarks the JAX-based heat simulator against the NumPy implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'data', 'Heat_Signature_zero-starter_notebook'))\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Backend: {jax.default_backend()}\")\n",
    "print(f\"Devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "data_path = os.path.join(os.getcwd(), '..', 'data', 'Heat_Signature_zero-starter_notebook', 'test_data.pkl')\n",
    "with open(data_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "meta = test_data['meta']\n",
    "samples = test_data['samples']\n",
    "print(f\"Loaded {len(samples)} samples\")\n",
    "print(f\"Meta: dt={meta['dt']}, q_range={meta['q_range']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test JAX Simulator Correctness\n",
    "\n",
    "First, let's verify the JAX simulator produces similar results to the NumPy version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import Heat2D\n",
    "from jax_simulator import JAXHeatSimulator, check_gpu\n",
    "\n",
    "# Check GPU availability\n",
    "gpu_info = check_gpu()\n",
    "print(\"GPU Info:\", gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "Lx, Ly = 2.0, 1.0\n",
    "nx, ny = 100, 50\n",
    "kappa = 0.01\n",
    "dt = 0.01\n",
    "nt = 100\n",
    "bc = 'dirichlet'\n",
    "T0 = 0.0\n",
    "\n",
    "# Test source\n",
    "sources = [{'x': 1.0, 'y': 0.5, 'q': 1.0}]\n",
    "sensors_xy = np.array([[0.5, 0.25], [1.0, 0.5], [1.5, 0.75]])\n",
    "\n",
    "print(\"Test configuration:\")\n",
    "print(f\"  Grid: {nx}x{ny}\")\n",
    "print(f\"  Domain: {Lx}x{Ly}\")\n",
    "print(f\"  Time steps: {nt} (dt={dt})\")\n",
    "print(f\"  Source: {sources[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy simulation\n",
    "solver_np = Heat2D(Lx, Ly, nx, ny, kappa, bc=bc)\n",
    "times_np, Us_np = solver_np.solve(dt=dt, nt=nt, T0=T0, sources=sources)\n",
    "Y_np = np.array([solver_np.sample_sensors(U, sensors_xy) for U in Us_np])\n",
    "\n",
    "print(f\"NumPy result shape: {Y_np.shape}\")\n",
    "print(f\"NumPy final temps at sensors: {Y_np[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX simulation\n",
    "solver_jax = JAXHeatSimulator(Lx, Ly, nx, ny)\n",
    "Y_jax = solver_jax.simulate_and_sample(sources, sensors_xy, kappa, dt, nt, bc, T0)\n",
    "\n",
    "print(f\"JAX result shape: {Y_jax.shape}\")\n",
    "print(f\"JAX final temps at sensors: {Y_jax[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "diff = np.abs(Y_np - Y_jax)\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Max absolute difference: {np.max(diff):.6e}\")\n",
    "print(f\"  Mean absolute difference: {np.mean(diff):.6e}\")\n",
    "print(f\"  Relative error: {np.max(diff) / (np.max(np.abs(Y_np)) + 1e-10):.6e}\")\n",
    "\n",
    "if np.max(diff) < 0.1:\n",
    "    print(\"\\n✓ JAX and NumPy results match within tolerance!\")\n",
    "else:\n",
    "    print(\"\\n✗ Results differ significantly - check implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i in range(len(sensors_xy)):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=times_np, y=Y_np[:, i],\n",
    "        mode='lines',\n",
    "        name=f'NumPy Sensor {i+1}',\n",
    "        line=dict(color=colors[i], dash='solid')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=times_np, y=Y_jax[:, i],\n",
    "        mode='lines',\n",
    "        name=f'JAX Sensor {i+1}',\n",
    "        line=dict(color=colors[i], dash='dash')\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='NumPy vs JAX Simulation Comparison',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Temperature',\n",
    "    height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmark: JAX vs NumPy Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_simulation(n_runs=10):\n",
    "    \"\"\"Benchmark simulation speed.\"\"\"\n",
    "    \n",
    "    # Warm up JAX (JIT compilation)\n",
    "    print(\"Warming up JAX (JIT compilation)...\")\n",
    "    _ = solver_jax.simulate_and_sample(sources, sensors_xy, kappa, dt, nt, bc, T0)\n",
    "    \n",
    "    # NumPy benchmark\n",
    "    print(f\"\\nRunning {n_runs} NumPy simulations...\")\n",
    "    start = time.time()\n",
    "    for _ in range(n_runs):\n",
    "        times_np, Us_np = solver_np.solve(dt=dt, nt=nt, T0=T0, sources=sources)\n",
    "        Y = np.array([solver_np.sample_sensors(U, sensors_xy) for U in Us_np])\n",
    "    numpy_time = (time.time() - start) / n_runs\n",
    "    print(f\"NumPy: {numpy_time*1000:.2f} ms per simulation\")\n",
    "    \n",
    "    # JAX benchmark\n",
    "    print(f\"\\nRunning {n_runs} JAX simulations...\")\n",
    "    start = time.time()\n",
    "    for _ in range(n_runs):\n",
    "        Y = solver_jax.simulate_and_sample(sources, sensors_xy, kappa, dt, nt, bc, T0)\n",
    "        # Block until computation completes\n",
    "        if hasattr(Y, 'block_until_ready'):\n",
    "            Y.block_until_ready()\n",
    "    jax_time = (time.time() - start) / n_runs\n",
    "    print(f\"JAX: {jax_time*1000:.2f} ms per simulation\")\n",
    "    \n",
    "    speedup = numpy_time / jax_time\n",
    "    print(f\"\\nSpeedup: {speedup:.2f}x\")\n",
    "    \n",
    "    return {'numpy_ms': numpy_time*1000, 'jax_ms': jax_time*1000, 'speedup': speedup}\n",
    "\n",
    "results = benchmark_simulation(n_runs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test JAX Automatic Differentiation\n",
    "\n",
    "The key advantage of JAX is automatic differentiation - we can compute exact gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a real sample\n",
    "sample = samples[0]\n",
    "Y_observed = sample['Y_noisy']\n",
    "sensors_xy_sample = np.array(sample['sensors_xy'])\n",
    "n_sources = sample['n_sources']\n",
    "\n",
    "print(f\"Sample: {sample['sample_id']}\")\n",
    "print(f\"  n_sources: {n_sources}\")\n",
    "print(f\"  n_sensors: {len(sensors_xy_sample)}\")\n",
    "print(f\"  Y_observed shape: {Y_observed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test gradient computation\n",
    "sample_meta = sample['sample_metadata']\n",
    "kappa_s = sample_meta['kappa']\n",
    "bc_s = sample_meta['bc']\n",
    "T0_s = sample_meta['T0']\n",
    "nt_s = sample_meta['nt']\n",
    "\n",
    "# Create a test source guess\n",
    "test_sources = [{'x': 1.0, 'y': 0.5, 'q': 1.0}]\n",
    "if n_sources == 2:\n",
    "    test_sources.append({'x': 0.5, 'y': 0.3, 'q': 0.8})\n",
    "\n",
    "print(f\"Computing objective and gradient for sources: {test_sources}\")\n",
    "\n",
    "# Compute objective\n",
    "rmse = solver_jax.compute_objective(\n",
    "    test_sources, Y_observed, sensors_xy_sample,\n",
    "    kappa_s, meta['dt'], nt_s, bc_s, T0_s\n",
    ")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "\n",
    "# Compute gradient\n",
    "grads = solver_jax.compute_gradient(\n",
    "    test_sources, Y_observed, sensors_xy_sample,\n",
    "    kappa_s, meta['dt'], nt_s, bc_s, T0_s\n",
    ")\n",
    "print(f\"Gradients shape: {grads.shape}\")\n",
    "print(f\"Gradients: {grads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify gradient with finite differences\n",
    "print(\"\\nVerifying gradients with finite differences...\")\n",
    "eps = 1e-4\n",
    "sources_arr = np.array([[s['x'], s['y'], s['q']] for s in test_sources])\n",
    "\n",
    "fd_grads = np.zeros_like(sources_arr)\n",
    "for i in range(sources_arr.shape[0]):\n",
    "    for j in range(sources_arr.shape[1]):\n",
    "        sources_plus = sources_arr.copy()\n",
    "        sources_plus[i, j] += eps\n",
    "        sources_minus = sources_arr.copy()\n",
    "        sources_minus[i, j] -= eps\n",
    "        \n",
    "        sources_p = [{'x': s[0], 'y': s[1], 'q': s[2]} for s in sources_plus]\n",
    "        sources_m = [{'x': s[0], 'y': s[1], 'q': s[2]} for s in sources_minus]\n",
    "        \n",
    "        f_plus = solver_jax.compute_objective(\n",
    "            sources_p, Y_observed, sensors_xy_sample,\n",
    "            kappa_s, meta['dt'], nt_s, bc_s, T0_s\n",
    "        )\n",
    "        f_minus = solver_jax.compute_objective(\n",
    "            sources_m, Y_observed, sensors_xy_sample,\n",
    "            kappa_s, meta['dt'], nt_s, bc_s, T0_s\n",
    "        )\n",
    "        fd_grads[i, j] = (f_plus - f_minus) / (2 * eps)\n",
    "\n",
    "print(f\"\\nAutomatic diff gradients:\\n{grads}\")\n",
    "print(f\"\\nFinite diff gradients:\\n{fd_grads}\")\n",
    "print(f\"\\nDifference:\\n{np.abs(grads - fd_grads)}\")\n",
    "print(f\"\\nMax difference: {np.max(np.abs(grads - fd_grads)):.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test JAX Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_optimizer import JAXOptimizer\n",
    "\n",
    "# Create optimizer\n",
    "jax_opt = JAXOptimizer(Lx, Ly, nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization on a sample\n",
    "print(f\"Optimizing sample: {sample['sample_id']}\")\n",
    "print(f\"  n_sources: {sample['n_sources']}\")\n",
    "print(f\"  bc: {sample['sample_metadata']['bc']}\")\n",
    "\n",
    "# Use Adam optimizer\n",
    "est_sources, rmse = jax_opt.estimate_sources_adam(\n",
    "    sample, meta,\n",
    "    q_range=meta['q_range'],\n",
    "    n_restarts=3,\n",
    "    max_iter=100,\n",
    "    learning_rate=0.05,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Estimated sources: {est_sources}\")\n",
    "print(f\"  RMSE: {rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare JAX vs NumPy Optimizer Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import HeatSourceOptimizer\n",
    "\n",
    "# NumPy optimizer\n",
    "np_opt = HeatSourceOptimizer(Lx, Ly, nx, ny)\n",
    "\n",
    "# Get a sample with single source for simpler comparison\n",
    "single_source_samples = [s for s in samples if s['n_sources'] == 1]\n",
    "test_sample = single_source_samples[0] if single_source_samples else samples[0]\n",
    "print(f\"Testing on sample: {test_sample['sample_id']} (n_sources={test_sample['n_sources']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark NumPy optimizer\n",
    "print(\"Running NumPy optimizer (L-BFGS-B, 3 restarts)...\")\n",
    "start = time.time()\n",
    "np_sources, np_rmse = np_opt.estimate_sources(\n",
    "    test_sample, meta,\n",
    "    q_range=meta['q_range'],\n",
    "    method='L-BFGS-B',\n",
    "    n_restarts=3,\n",
    "    max_iter=100\n",
    ")\n",
    "np_time = time.time() - start\n",
    "print(f\"NumPy: {np_time:.2f}s, RMSE={np_rmse:.6f}\")\n",
    "print(f\"  Sources: {np_sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark JAX optimizer\n",
    "print(\"\\nRunning JAX optimizer (Adam, 3 restarts)...\")\n",
    "start = time.time()\n",
    "jax_sources, jax_rmse = jax_opt.estimate_sources_adam(\n",
    "    test_sample, meta,\n",
    "    q_range=meta['q_range'],\n",
    "    n_restarts=3,\n",
    "    max_iter=100,\n",
    "    learning_rate=0.05,\n",
    "    verbose=False\n",
    ")\n",
    "jax_time = time.time() - start\n",
    "print(f\"JAX: {jax_time:.2f}s, RMSE={jax_rmse:.6f}\")\n",
    "print(f\"  Sources: {jax_sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIMIZATION BENCHMARK SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"NumPy (L-BFGS-B): {np_time:.2f}s, RMSE={np_rmse:.6f}\")\n",
    "print(f\"JAX (Adam):       {jax_time:.2f}s, RMSE={jax_rmse:.6f}\")\n",
    "print(f\"\\nTime ratio: JAX is {np_time/jax_time:.2f}x {'faster' if jax_time < np_time else 'slower'}\")\n",
    "print(f\"RMSE comparison: JAX is {'better' if jax_rmse < np_rmse else 'worse'} by {abs(jax_rmse - np_rmse):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate with estimated sources and compare\n",
    "Y_observed = test_sample['Y_noisy']\n",
    "sensors = np.array(test_sample['sensors_xy'])\n",
    "sample_meta = test_sample['sample_metadata']\n",
    "\n",
    "# Simulate with JAX estimated sources\n",
    "jax_est_dicts = [{'x': s[0], 'y': s[1], 'q': s[2]} for s in jax_sources]\n",
    "Y_jax_pred = solver_jax.simulate_and_sample(\n",
    "    jax_est_dicts, sensors,\n",
    "    sample_meta['kappa'], meta['dt'], sample_meta['nt'],\n",
    "    sample_meta['bc'], sample_meta['T0']\n",
    ")\n",
    "\n",
    "# Plot comparison\n",
    "times = np.arange(len(Y_observed)) * meta['dt']\n",
    "n_sensors = Y_observed.shape[1]\n",
    "\n",
    "fig = make_subplots(rows=n_sensors, cols=1, \n",
    "                    subplot_titles=[f'Sensor {i+1}' for i in range(n_sensors)])\n",
    "\n",
    "for i in range(n_sensors):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=times, y=Y_observed[:, i], mode='lines', \n",
    "                   name=f'Observed {i+1}', line=dict(color='blue')),\n",
    "        row=i+1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=times, y=Y_jax_pred[:, i], mode='lines',\n",
    "                   name=f'JAX Pred {i+1}', line=dict(color='red', dash='dash')),\n",
    "        row=i+1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Observed vs JAX Predicted (RMSE={jax_rmse:.4f})',\n",
    "    height=200*n_sensors,\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key findings:\n",
    "1. **Correctness**: JAX simulator produces results matching NumPy within numerical tolerance\n",
    "2. **Speed**: JAX with JIT compilation provides speedup (varies by hardware)\n",
    "3. **Autodiff**: JAX provides exact gradients, verified against finite differences\n",
    "4. **Optimization**: JAX optimizer with Adam can achieve competitive RMSE\n",
    "\n",
    "Note: For GPU acceleration, you would need to install JAX with CUDA support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

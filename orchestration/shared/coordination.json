{
  "version": "5.3",
  "last_updated": "2026-01-19T06:00:00Z",
  "mode": "EXPLORATION",

  "resume_tracking": {
    "summaries_analyzed": ["ensemble_voting", "cluster_transfer", "lq_cma_es_builtin", "bayesian_optimization_gp", "cmaes_to_nm_sequential", "multi_fidelity_pyramid", "fast_source_count_detection", "early_timestep_filtering", "adaptive_sample_budget", "warm_start_cmaes"],
    "last_cycle_timestamp": "2026-01-19T06:15:00Z",
    "notes": "W0 tracks which SUMMARY.md files have been analyzed to avoid re-processing on resume"
  },

  "best_scores": {
    "in_budget": {
      "score": 1.1688,
      "time_min": 58.4,
      "experiment": "early_timestep_filtering",
      "algorithm": "CMA-ES + 40% temporal fidelity + 8 NM polish (full timesteps)",
      "date": "2026-01-19",
      "note": "NEW BEST! +0.0441 vs original baseline (1.1247), within budget"
    },
    "best_ever": {
      "score": 1.1396,
      "time_min": 68.3,
      "experiment": "adaptive_sigma",
      "algorithm": "CMA-ES (sigma=0.30/0.35)",
      "note": "OVER BUDGET by 8.3 min",
      "date": "2026-01-18"
    },
    "best_accuracy": {
      "score": 1.0422,
      "time_min": 87.0,
      "experiment": "ica_decomposition",
      "algorithm": "ICA",
      "note": "OVER BUDGET by 27 min - proves accuracy headroom exists",
      "date": "2026-01-05"
    },
    "target": 1.25,
    "baseline_to_beat": 1.1688
  },

  "queue_status": {
    "available_experiments": 5,
    "claimed_experiments": 1,
    "status": "HEALTHY",
    "experiments": [
      "EXP_TEMPORAL_HIGHER_SIGMA_001 (priority 1) - CLAIMED by W1",
      "EXP_NICHING_CMAES_001 (priority 2)",
      "EXP_IPOP_TEMPORAL_001 (priority 3)",
      "EXP_PHYSICS_INIT_001 (priority 4)",
      "EXP_ADAPTIVE_TIMESTEP_001 (priority 5)",
      "EXP_POD_SURROGATE_001 (priority 6)"
    ]
  },

  "exploration_progress": {
    "total_experiments": 58,
    "experiments_per_family": {
      "evolutionary_cmaes": 34,
      "evolutionary_other": 3,
      "gradient_based": 4,
      "gradient_free_local": 6,
      "surrogate": 2,
      "surrogate_lq": 1,
      "ensemble": 1,
      "decomposition": 2,
      "meta_learning": 3,
      "hybrid": 1,
      "bayesian_opt": 1,
      "multi_fidelity": 1,
      "temporal_fidelity": 1,
      "budget_allocation": 1
    },
    "families_exhausted": ["evolutionary_cmaes", "gradient_based", "evolutionary_other", "ensemble", "decomposition", "meta_learning", "surrogate_lq", "bayesian_opt", "multi_fidelity", "hybrid", "preprocessing", "budget_allocation", "diversity"],
    "families_to_explore": ["temporal_fidelity_extended", "initialization", "surrogate_pod"]
  },

  "experiments_in_progress": {
    "EXP_TEMPORAL_HIGHER_SIGMA_001": {
      "worker": "W1",
      "claimed_at": "2026-01-19T06:00:00Z",
      "status": "running"
    }
  },

  "experiments_completed": [
    {
      "id": "EXP_NICHING_CMAES_001",
      "worker": "W2",
      "score": 1.0622,
      "time_min": 46.9,
      "result": "FAILED",
      "family": "diversity",
      "note": "Niching FAILED. Scoring averages accuracy over candidates - worse diverse candidates hurt. Baseline already at 2.75/3 N_valid."
    },
    {
      "id": "EXP_TEMPORAL_FIDELITY_001",
      "worker": "W2",
      "score": 1.1688,
      "time_min": 58.4,
      "result": "SUCCESS",
      "family": "temporal_fidelity",
      "note": "NEW BEST! 40% timesteps + 8 NM polish (full): +0.0441 vs baseline. 2-src RMSE dropped 33%."
    },
    {
      "id": "EXP_ADAPTIVE_BUDGET_001",
      "worker": "W1",
      "score": 1.1143,
      "time_min": 56.2,
      "result": "FAILED",
      "family": "budget_allocation",
      "note": "Early termination hurts CMA-ES accuracy. Fixed-budget baseline is optimal."
    },
    {
      "id": "EXP_WS_CMAES_001",
      "worker": "W1",
      "score": 0.276,
      "time_min": 65.8,
      "result": "FAILED",
      "family": "meta_learning",
      "note": "WS-CMA-ES causes divergence. Probing wastes budget. meta_learning family EXHAUSTED."
    },
    {
      "id": "EXP_FAST_SOURCE_DETECT_001",
      "worker": "W2",
      "score": null,
      "time_min": null,
      "result": "ABORTED",
      "family": "preprocessing",
      "note": "INVALID PREMISE - n_sources already in sample data."
    },
    {
      "id": "EXP_SEQUENTIAL_HANDOFF_001",
      "worker": "W2",
      "score": 1.1132,
      "time_min": 56.6,
      "result": "FAILED",
      "family": "hybrid",
      "note": "Sequential CMA-ES to NM handoff FAILED. Best in-budget 1.1132 is WORSE than baseline."
    },
    {
      "id": "EXP_MULTIFID_OPT_001",
      "worker": "W1",
      "score": 0.259,
      "time_min": 44.9,
      "result": "FAILED",
      "family": "multi_fidelity",
      "note": "Coarse grid RMSE landscape differs from fine grid."
    },
    {
      "id": "EXP_BAYESIAN_OPT_001",
      "worker": "W1",
      "score": 0.31,
      "time_min": 57.6,
      "result": "FAILED",
      "family": "bayesian_opt",
      "note": "GP surrogate doesn't model thermal RMSE landscape."
    },
    {
      "id": "EXP_LQ_CMAES_001",
      "worker": "W1",
      "score": 0.253,
      "time_min": 64.1,
      "result": "FAILED",
      "family": "surrogate_lq",
      "note": "fmin_lq_surr API mismatch - returns ONE solution but we need MULTIPLE candidates."
    },
    {
      "id": "EXP_TRANSFER_LEARN_001",
      "worker": "W2",
      "score": 1.0804,
      "time_min": 59.7,
      "result": "FAILED",
      "family": "meta_learning",
      "note": "Cluster transfer FAILED - sensor features don't predict solution similarity."
    },
    {
      "id": "EXP_ENSEMBLE_001",
      "worker": "W1",
      "score": 1.0972,
      "time_min": 347.9,
      "result": "FAILED",
      "family": "ensemble",
      "note": "Ensemble 5.8x over budget."
    },
    {
      "id": "CMAES_TUNING_BATCH",
      "worker": "ALL",
      "score": 1.1247,
      "time_min": 57.2,
      "result": "EXHAUSTED",
      "family": "evolutionary_cmaes",
      "note": "32+ experiments. Best in-budget: 1.1247."
    }
  ],

  "workers": {
    "W1": {
      "status": "running",
      "current_experiment": "EXP_TEMPORAL_HIGHER_SIGMA_001",
      "last_completed": "EXP_ADAPTIVE_BUDGET_001",
      "directive": "Running temporal_40pct_higher_sigma - combining 40% timesteps with higher sigma"
    },
    "W2": {
      "status": "idle",
      "current_experiment": null,
      "last_completed": "EXP_NICHING_CMAES_001",
      "directive": "Niching FAILED. Diversity is NOT the bottleneck. Pick next available experiment."
    },
    "W3": {
      "status": "idle",
      "current_experiment": null,
      "last_completed": null,
      "directive": "NEW BEST 1.1688! Use optimizer_with_polish.py. Focus on diversity improvements if any headroom remains."
    },
    "W4": {
      "status": "idle",
      "current_experiment": null,
      "last_completed": null,
      "directive": "NEW BEST 1.1688! Use optimizer_with_polish.py. Only 1.6 min headroom - marginal gains only."
    }
  },

  "research_findings": [
    "CMA-ES covariance adaptation is ESSENTIAL - no algorithm replacement works",
    "PSO FAILED: faster but terrible 1-src accuracy - lacks covariance adaptation",
    "COBYLA FAILED: better accuracy but 55% slower than Nelder-Mead refinement",
    "SURROGATE NN FAILED: Online learning doesn't work with parallel processing",
    "Sigma-time tradeoff is FUNDAMENTAL - no free lunch",
    "L-BFGS-B makes gradient methods 10-50x more expensive (finite differences)",
    "------- W2 EXP_TEMPORAL_FIDELITY_001 SUCCESS (2026-01-19) -------",
    "BREAKTHROUGH: 40% timesteps achieves 1.1362 @ 39 min (+0.0115 vs baseline, 32% faster)",
    "KEY INSIGHT: Temporal fidelity works because spatial grid remains intact (100x50)",
    "Unlike spatial coarsening (FAILED), truncated time series maintains RMSE landscape correlation",
    "Correlation test: 40% timesteps gives 0.95+ Spearman correlation with full RMSE",
    "SWEET SPOT: 40% timesteps optimal. Below 40% = too noisy, above 40% = diminishing returns",
    "COUNTERINTUITIVE: More fevals with truncated signal HURTS (overfits to noisy proxy)",
    "------- W2 EXP_TEMPORAL_FIDELITY_001 POLISH UPDATE (2026-01-19) -------",
    "MAJOR BREAKTHROUGH: 40% timesteps + 8 NM polish (full) = 1.1688 @ 58.4 min",
    "CRITICAL: NM polish must use FULL timesteps, not truncated (polishing proxy overfits to noise)",
    "2-source RMSE dropped from 0.21 to 0.14 (33% reduction) with full-timestep polish",
    "NEW BASELINE: 1.1688 @ 58.4 min (early_timestep_filtering with 8 NM polish)",
    "------- W1 EXP_ADAPTIVE_BUDGET_001 FAILED (2026-01-19) -------",
    "Early termination based on sigma/stagnation hurts accuracy",
    "CMA-ES needs full budget to properly adapt covariance matrix",
    "Fixed-budget approach is already near-optimal",
    "------- STRATEGY UPDATE (2026-01-19) -------",
    "NEW BEST EVER IN-BUDGET: 1.1688 surpasses previous best-ever (1.1396 was over budget)",
    "Key recipe: CMA-ES (40% timesteps) + NM polish (full timesteps) = fast exploration + accurate refinement",
    "Remaining gap to target (1.25): 0.0612 - marginal gains now, diminishing returns expected",
    "CONCLUSION: Temporal fidelity + full-timestep polish is optimal strategy",
    "------- W2 EXP_NICHING_CMAES_001 FAILED (2026-01-19) -------",
    "CRITICAL: Scoring formula AVERAGES accuracy: score = (1/N)*sum(1/(1+L_i)) + 0.3*(N/3)",
    "Adding diverse but worse candidates HURTS the score more than diversity bonus helps",
    "Baseline already achieves 2.75/3 N_valid (80% of samples have 3 candidates)",
    "Taboo-based niching pushes CMA-ES to suboptimal solutions",
    "CONCLUSION: Diversity is NOT the bottleneck. Focus on accuracy improvement only."
  ],

  "research_sources": [
    "https://github.com/CMA-ES/pycma - pycma with lq-CMA-ES support",
    "https://github.com/CMA-ES/lq-cma - Official lq-CMA-ES implementation",
    "https://arxiv.org/html/2402.09638v1 - Multi-Fidelity Methods Survey",
    "https://www.sciencedirect.com/science/article/abs/pii/S0378778811000533 - Rapid PDE optimization"
  ],

  "notes": "V5.3 NEW BEST: 1.1688 @ 58.4 min (40% timesteps + 8 NM polish on full timesteps). Surpasses previous best-ever 1.1396. Only 1.6 min headroom remaining. Consider this the production configuration."
}
